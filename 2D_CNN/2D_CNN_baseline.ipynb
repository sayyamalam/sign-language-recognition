{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMB7HdNVZXi2DG1wm/7KVop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayyamalam/sign-language-recognition/blob/main/2D_CNN/2D_CNN_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPavwPjF9Yth",
        "outputId": "9fd298a3-ec05-41bd-b1c7-f63d78cb0451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.4/247.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m703.4/703.4 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Nur fehlende Pakete installieren\n",
        "%pip install -q --upgrade-strategy only-if-needed mlflow pyyaml\n",
        "%pip install -q --no-deps decord"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basis-Imports\n",
        "import os, json, random, math, time, pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import mlflow\n",
        "\n",
        "# decord (Video-Decode)\n",
        "try:\n",
        "    import decord\n",
        "    decord.bridge.set_bridge(\"native\")  # numpy-Arrays\n",
        "    _DECORD_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    print(\"Warnung: decord nicht verfügbar:\", e)\n",
        "    _DECORD_AVAILABLE = False\n",
        "\n",
        "# Drive mounten\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Standardpfade in Drive\n",
        "MLFLOW_DIR   = \"/content/drive/MyDrive/mlruns\"\n",
        "ARTIFACTS_DIR= \"/content/drive/MyDrive/ml_artifacts/msasl_selected50/3d_baseline\"\n",
        "DATA_ROOT    = \"/content/drive/MyDrive/msasl_clips\"\n",
        "SELECTED_DIR = \"/content/sign-language-recognition/meta/selected50\"\n",
        "\n",
        "# Ordner anlegen\n",
        "os.makedirs(MLFLOW_DIR, exist_ok=True)\n",
        "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
        "\n",
        "def device_report():\n",
        "    print(\"TensorFlow:\", tf.__version__)\n",
        "    print(\"NumPy:\", np.__version__)\n",
        "    print(\"Pandas:\", pd.__version__)\n",
        "    print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "device_report()\n",
        "\n",
        "# Performance-Flags\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "tf.config.optimizer.set_jit(True)\n",
        "print(\"Mixed precision:\", tf.keras.mixed_precision.global_policy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5YSrXKY9e06",
        "outputId": "16845464-9935-4459-df08-a19fe2915537"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "TensorFlow: 2.19.0\n",
            "NumPy: 2.0.2\n",
            "Pandas: 2.2.2\n",
            "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Mixed precision: <DTypePolicy \"mixed_float16\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mini-Config (Baseline hart codiert)\n",
        "CFG = dict(\n",
        "    # Pfade\n",
        "    DRIVE_ROOT=DATA_ROOT,\n",
        "    SELECTED_DIR=SELECTED_DIR,\n",
        "    ARTIFACTS_DIR=ARTIFACTS_DIR,\n",
        "    MLFLOW_URI=MLFLOW_DIR,\n",
        "\n",
        "    # MLflow Identität\n",
        "    EXPERIMENT_NAME=\"MSASL_selected50\",\n",
        "    RUN_GROUP=\"3D_BASELINE\",\n",
        "    MODEL_FAMILY=\"3D\",\n",
        "\n",
        "    # Daten\n",
        "    T=16, STRIDE=2, IMG_SIZE=160, BATCH=8,\n",
        "    AUG=\"light\", CROP_POLICY=\"box_1.2x\", PAD_MODE=\"repeat\",\n",
        "\n",
        "    # Training\n",
        "    EPOCHS=30, BASE_LR=3e-4, WEIGHT_DECAY=1e-4,\n",
        "    WARMUP_EPOCHS=2, COSINE=True, CLIP_NORM=5.0,\n",
        "\n",
        "    # Debug\n",
        "    DRY_RUN=False, MAX_STEPS=0, EVAL_MAX_BATCHES=0, SKIP_DECODE=False,\n",
        "    LIMIT_SAMPLES=dict(train=None, val=None, test=None),\n",
        "\n",
        "    # Modell\n",
        "    BACKBONE=\"i3d_baseline\",\n",
        "    FINE_TUNE=\"linear\",\n",
        "    HEAD_TYPE=\"gap_fc\", HEAD_DIM=512, DROPOUT=0.3,\n",
        "    LABEL_SMOOTHING=0.0,\n",
        ")\n",
        "\n",
        "# Falls decord fehlt und Decoding vorgesehen war → Dummy-Frames\n",
        "if not _DECORD_AVAILABLE and not CFG[\"SKIP_DECODE\"]:\n",
        "    print(\"decord nicht verfügbar – schalte SKIP_DECODE=True (Dummy-Frames).\")\n",
        "    CFG[\"SKIP_DECODE\"] = True\n",
        "\n",
        "# --- MLflow robust initialisieren (repariert defektes .trash) ---\n",
        "import mlflow\n",
        "def _ensure_mlflow_dir_ok(path: str):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    trash = os.path.join(path, \".trash\")\n",
        "    if os.path.exists(trash) and not os.path.isdir(trash):\n",
        "        # defektes .trash (z. B. Datei) entfernen\n",
        "        os.remove(trash)\n",
        "    os.makedirs(trash, exist_ok=True)\n",
        "\n",
        "_ensure_mlflow_dir_ok(CFG[\"MLFLOW_URI\"])\n",
        "mlflow.end_run()\n",
        "mlflow.set_tracking_uri(CFG[\"MLFLOW_URI\"])\n",
        "mlflow.set_experiment(CFG[\"EXPERIMENT_NAME\"])\n",
        "\n",
        "def mlflow_start(run_name: str, tags: dict, params: dict = None):\n",
        "    run = mlflow.start_run(run_name=run_name)\n",
        "    mlflow.set_tags(tags)\n",
        "    if params:\n",
        "        to_log = {}\n",
        "        for k,v in params.items():\n",
        "            to_log[k] = float(v) if isinstance(v, (np.floating,)) else v\n",
        "        mlflow.log_params(to_log)\n",
        "    try:\n",
        "        mlflow.tensorflow.autolog(log_models=True)\n",
        "    except Exception as e:\n",
        "        print(\"mlflow autolog Warnung:\", e)\n",
        "    return run\n",
        "\n",
        "def mlflow_log_metrics(metrics: dict, step: int = None):\n",
        "    if not metrics: return\n",
        "    mlflow.log_metrics({k: float(v) for k, v in metrics.items()}, step=step)\n",
        "\n",
        "def mlflow_log_artifact(path: str, artifact_path: str = None):\n",
        "    if os.path.exists(path):\n",
        "        mlflow.log_artifact(path, artifact_path=artifact_path)\n",
        "\n",
        "def mlflow_end():\n",
        "    mlflow.end_run()\n",
        "\n",
        "print(\"MLflow bereit:\", mlflow.get_tracking_uri())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcjzz1iv9z--",
        "outputId": "2533ee1c-87c9-49c8-8d41-5d6e40ec5257"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow bereit: /content/drive/MyDrive/mlruns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, glob, shutil\n",
        "\n",
        "def youtube_id_from_url(url: str) -> str:\n",
        "    \"\"\"Extrahiert YouTube-ID aus URL.\"\"\"\n",
        "    m = re.search(r\"(?:v=|youtu\\.be/)([A-Za-z0-9_\\-]{6,})\", url)\n",
        "    if m: return m.group(1)\n",
        "    return url.split(\"v=\")[-1].split(\"&\")[0]\n",
        "\n",
        "def _slug(s: str, maxlen: int = 40) -> str:\n",
        "    \"\"\"Säubert Texte für Dateinamen.\"\"\"\n",
        "    s = re.sub(r\"\\s+\", \"_\", str(s).strip())\n",
        "    s = re.sub(r\"[^\\w\\-]+\", \"_\", s)\n",
        "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
        "    return s[:maxlen] if maxlen else s\n",
        "\n",
        "def _ts_token(start: float, end: float) -> str:\n",
        "    \"\"\"Erzeugt Zeitstempel-Token in ms.\"\"\"\n",
        "    s_ms = int(round(float(start) * 1000.0))\n",
        "    e_ms = int(round(float(end)   * 1000.0))\n",
        "    return f\"{s_ms:07d}-{e_ms:07d}ms\"\n",
        "\n",
        "def make_filename(entry: dict) -> str:\n",
        "    \"\"\"Baut Dateinamen exakt wie im Downloader.\"\"\"\n",
        "    ytid  = youtube_id_from_url(entry[\"url\"])\n",
        "    split = entry[\"split\"]\n",
        "    label = int(entry.get(\"label\", -1))\n",
        "    signer_id = entry.get(\"signer_id\", \"na\")\n",
        "\n",
        "    start = float(entry.get(\"start_time\", 0.0))\n",
        "    end   = float(entry.get(\"end_time\",   0.0))\n",
        "    if end <= start: end = start + 3.0\n",
        "    ts = _ts_token(start, end)\n",
        "\n",
        "    clean_text = _slug(entry.get(\"clean_text\", \"na\"), maxlen=40)\n",
        "    return f\"{ytid}__s-{ts}__lab-{label}__sig-{signer_id}__{clean_text}__{split}.mp4\"\n",
        "\n",
        "def load_split_index(selected_dir: str) -> dict:\n",
        "    \"\"\"Lädt JSONs und baut DataFrames mit Dateinamen wie im Downloader.\"\"\"\n",
        "    files = {\"train\": \"MSASL_train_selected50.json\",\n",
        "             \"val\":   \"MSASL_val_selected50.json\",\n",
        "             \"test\":  \"MSASL_test_selected50.json\"}\n",
        "    out = {}\n",
        "    for split, fname in files.items():\n",
        "        path = os.path.join(selected_dir, fname)\n",
        "        with open(path, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "        recs = []\n",
        "        for it in data:\n",
        "            it[\"split\"] = split\n",
        "            fn = make_filename(it)\n",
        "            recs.append({\n",
        "                \"label\": str(it.get(\"label\")),\n",
        "                \"filename\": fn,\n",
        "                \"box\": it.get(\"box\") or None,\n",
        "                \"split\": split\n",
        "            })\n",
        "        out[split] = pd.DataFrame.from_records(recs)\n",
        "    return out\n",
        "\n",
        "def build_class_mapping(dfs: dict):\n",
        "    labels = pd.concat([dfs[\"train\"][\"label\"], dfs[\"val\"][\"label\"], dfs[\"test\"][\"label\"]]).unique()\n",
        "    class_names = sorted([str(x) for x in labels])\n",
        "    label_to_id = {c: i for i, c in enumerate(class_names)}\n",
        "    return label_to_id, class_names\n",
        "\n",
        "# --- Lade Indexe ---\n",
        "dfs = load_split_index(CFG[\"SELECTED_DIR\"])\n",
        "label_to_id, class_names = build_class_mapping(dfs)\n",
        "num_classes = len(class_names)\n",
        "print(\"Splits:\", {k: len(v) for k, v in dfs.items()}, \"| num_classes:\", num_classes)\n",
        "\n",
        "# --- Lokales Mirror-Directory für Geschwindigkeit ---\n",
        "LOCAL_DATA_ROOT = \"/content/msasl_clips_local\"\n",
        "if not os.path.exists(LOCAL_DATA_ROOT):\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        src = os.path.join(CFG[\"DRIVE_ROOT\"], split)\n",
        "        dst = os.path.join(LOCAL_DATA_ROOT, split)\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "        files = glob.glob(f\"{src}/**/*.mp4\", recursive=True)[:500]  # Beispiel: nur 500 pro Split\n",
        "        for f in files:\n",
        "            rel = os.path.relpath(f, src)\n",
        "            dst_path = os.path.join(dst, rel)\n",
        "            os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "            if not os.path.exists(dst_path):\n",
        "                shutil.copy2(f, dst_path)\n",
        "    print(\"✅ Clips lokal gespiegelt:\", LOCAL_DATA_ROOT)\n",
        "\n",
        "# CFG umschalten auf lokale Daten\n",
        "CFG[\"DRIVE_ROOT\"] = LOCAL_DATA_ROOT\n",
        "\n",
        "# --- Quick Check ---\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    df = dfs[split].head(3)\n",
        "    for _, row in df.iterrows():\n",
        "        p = os.path.join(CFG[\"DRIVE_ROOT\"], split, row[\"label\"], row[\"filename\"])\n",
        "        print(split, \"→\", os.path.exists(p), p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v-8XF0g-AKb",
        "outputId": "88f0a179-be3b-4f99-9631-e55f9af7e892"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splits: {'train': 1677, 'val': 374, 'test': 248} | num_classes: 50\n",
            "✅ Clips lokal gespiegelt: /content/msasl_clips_local\n",
            "train → True /content/msasl_clips_local/train/8/jQb9NL9_S6U__s-0385765-0392077ms__lab-8__sig-6__want__train.mp4\n",
            "train → True /content/msasl_clips_local/train/29/jQb9NL9_S6U__s-0433452-0437071ms__lab-29__sig-6__must__train.mp4\n",
            "train → True /content/msasl_clips_local/train/2/_HOx2QkkTsg__s-0013995-0015498ms__lab-2__sig-144__teacher__train.mp4\n",
            "val → True /content/msasl_clips_local/val/28/nhEw0JSb-XQ__s-0000000-0002933ms__lab-28__sig-3__table__val.mp4\n",
            "val → True /content/msasl_clips_local/val/13/koMZVbqiXf4__s-0151351-0154755ms__lab-13__sig-125__white__val.mp4\n",
            "val → True /content/msasl_clips_local/val/41/koMZVbqiXf4__s-0155956-0159126ms__lab-41__sig-125__black__val.mp4\n",
            "test → True /content/msasl_clips_local/test/51/G77ZoILMYw4__s-0080380-0083283ms__lab-51__sig-9__doctor__test.mp4\n",
            "test → True /content/msasl_clips_local/test/2/G77ZoILMYw4__s-0332331-0335301ms__lab-2__sig-9__teacher__test.mp4\n",
            "test → True /content/msasl_clips_local/test/79/cNtU2UH-2Rk__s-0176510-0181081ms__lab-79__sig-10__pencil__test.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_clip_path(drive_root: str, split: str, label: str, filename: str) -> str:\n",
        "    \"\"\"Baut den absoluten Pfad zu einem Clip.\"\"\"\n",
        "    return os.path.join(drive_root, split, label, filename)\n",
        "\n",
        "def sample_indices(num_frames: int, T: int, stride: int) -> np.ndarray:\n",
        "    if num_frames <= 0:\n",
        "        return np.zeros((T,), dtype=np.int64)\n",
        "    idx = np.arange(0, T*stride, stride, dtype=np.int64)\n",
        "    return np.clip(idx, 0, max(0, num_frames-1))\n",
        "\n",
        "def decode_clip(path: str, indices: np.ndarray) -> np.ndarray:\n",
        "    if CFG[\"SKIP_DECODE\"]:\n",
        "        return np.zeros((indices.shape[0], CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"], 3), dtype=np.uint8)\n",
        "    vr = decord.VideoReader(path, num_threads=2, ctx=decord.cpu(0))\n",
        "    indices = np.clip(indices, 0, len(vr)-1)\n",
        "    return vr.get_batch(indices.tolist()).asnumpy()\n",
        "\n",
        "def resize_and_box_crop(frames: np.ndarray, box, img_size: int, expand: float = 1.2) -> np.ndarray:\n",
        "    T, H, W = frames.shape[0], frames.shape[1], frames.shape[2]\n",
        "    if box is None:\n",
        "        side = min(H, W); y1=(H-side)//2; x1=(W-side)//2; y2=y1+side; x2=x1+side\n",
        "    else:\n",
        "        x1r,y1r,x2r,y2r = box\n",
        "        x1 = int(x1r*W); y1 = int(y1r*H); x2 = int(x2r*W); y2 = int(y2r*H)\n",
        "        cx,cy = (x1+x2)/2,(y1+y2)/2\n",
        "        bw=max(1,int((x2-x1)*expand)); bh=max(1,int((y2-y1)*expand))\n",
        "        x1=int(cx-bw/2); x2=int(cx+bw/2); y1=int(cy-bh/2); y2=int(cy+bh/2)\n",
        "        x1=max(0,x1); y1=max(0,y1); x2=min(W,x2); y2=min(H,y2)\n",
        "    out = []\n",
        "    for t in range(T):\n",
        "        img = frames[t, y1:y2, x1:x2, :]\n",
        "        img = tf.image.resize(img, (img_size, img_size), method=\"bilinear\").numpy().astype(np.uint8)\n",
        "        out.append(img)\n",
        "    return np.stack(out, axis=0)\n",
        "\n",
        "def augment_light(frames: np.ndarray, training: bool) -> np.ndarray:\n",
        "    if not training or CFG[\"AUG\"] in (None, \"none\"):\n",
        "        return frames\n",
        "    f = frames\n",
        "    if random.random() < 0.5:\n",
        "        f = f[:, :, ::-1, :]\n",
        "    ff = tf.convert_to_tensor(f, dtype=tf.float32)\n",
        "    ff = tf.image.random_brightness(ff, max_delta=0.05)\n",
        "    ff = tf.image.random_contrast(ff, lower=0.95, upper=1.05)\n",
        "    return tf.cast(tf.clip_by_value(ff, 0, 255), tf.uint8).numpy()\n"
      ],
      "metadata": {
        "id": "hchjMCn9-tHz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_split_dataframe(dfs: dict, split: str, limit: int | None) -> pd.DataFrame:\n",
        "    df = dfs[split]\n",
        "    if limit is not None:\n",
        "        df = df.sample(n=min(limit, len(df)), random_state=42).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def gen_examples(dfs: dict, split: str):\n",
        "    df = build_split_dataframe(dfs, split, CFG[\"LIMIT_SAMPLES\"].get(split))\n",
        "    for _, row in df.iterrows():\n",
        "        label = row[\"label\"]; label_id = label_to_id[label]\n",
        "        path = make_clip_path(CFG[\"DRIVE_ROOT\"], split, label, row[\"filename\"])\n",
        "        if not os.path.exists(path) and not CFG[\"SKIP_DECODE\"]:\n",
        "            continue\n",
        "        try:\n",
        "            if CFG[\"SKIP_DECODE\"]:\n",
        "                num_frames = CFG[\"T\"] * CFG[\"STRIDE\"]\n",
        "            else:\n",
        "                vr = decord.VideoReader(path, num_threads=1, ctx=decord.cpu(0))\n",
        "                num_frames = len(vr)\n",
        "            idx = sample_indices(num_frames, CFG[\"T\"], CFG[\"STRIDE\"])\n",
        "            frames = decode_clip(path, idx)\n",
        "        except Exception:\n",
        "            continue\n",
        "        frames = resize_and_box_crop(frames, row.get(\"box\"), CFG[\"IMG_SIZE\"], expand=1.2)\n",
        "        frames = augment_light(frames, training=(split == \"train\"))\n",
        "        yield frames, label_id\n",
        "\n",
        "def _to_tensor(frames, label_id):\n",
        "    x = tf.convert_to_tensor(frames, dtype=tf.uint8)\n",
        "    x = tf.image.convert_image_dtype(x, tf.float32)\n",
        "    y = tf.one_hot(label_id, depth=num_classes, dtype=tf.float32)\n",
        "    return x, y\n",
        "\n",
        "def _map_to_tensor(f, y):\n",
        "    x, y = tf.py_function(func=_to_tensor, inp=[f, y], Tout=(tf.float32, tf.float32))\n",
        "    x.set_shape((CFG[\"T\"], CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"], 3))\n",
        "    y.set_shape((num_classes,))\n",
        "    return x, y\n",
        "\n",
        "def build_dataset(dfs: dict, split: str, batch_size: int, shuffle: bool):\n",
        "    output_sig = (\n",
        "        tf.TensorSpec(shape=(CFG[\"T\"], CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"], 3), dtype=tf.uint8),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.int32),\n",
        "    )\n",
        "    ds = tf.data.Dataset.from_generator(lambda: gen_examples(dfs, split), output_signature=output_sig)\n",
        "    if shuffle: ds = ds.shuffle(buffer_size=2048, reshuffle_each_iteration=True)\n",
        "    ds = ds.map(_map_to_tensor, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False if shuffle else True)\n",
        "    ds = ds.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "ds_train = build_dataset(dfs, \"train\", CFG[\"BATCH\"], shuffle=True)\n",
        "ds_val   = build_dataset(dfs, \"val\",   CFG[\"BATCH\"], shuffle=False)\n",
        "ds_test  = build_dataset(dfs, \"test\",  CFG[\"BATCH\"], shuffle=False)\n",
        "\n",
        "xb, yb = next(iter(ds_train))\n",
        "print(\"Batch shapes:\", xb.shape, yb.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDDhIQGy_ATl",
        "outputId": "c96fe0ef-9fb9-4894-9c46-4bc698fd3abd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shapes: (8, 16, 160, 160, 3) (8, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, applications\n",
        "\n",
        "def build_2d_baseline(input_shape, num_classes, dropout=0.3):\n",
        "    \"\"\"\n",
        "    2D-Baseline: Pretrained MobileNetV3-Small als Frame-Encoder + Temporal Average.\n",
        "    \"\"\"\n",
        "    inp = layers.Input(shape=input_shape, dtype=tf.float32)  # (T, H, W, 3)\n",
        "\n",
        "    # Frames einzeln durch 2D-Backbone\n",
        "    x = layers.TimeDistributed(\n",
        "            applications.MobileNetV3Small(\n",
        "                include_top=False,\n",
        "                weights=\"imagenet\",\n",
        "                input_shape=input_shape[1:],  # (H, W, 3)\n",
        "                pooling=\"avg\"\n",
        "            )\n",
        "        )(inp)   # (T, feature_dim)\n",
        "\n",
        "    # Zeitliche Aggregation\n",
        "    x = layers.GlobalAveragePooling1D()(x)   # (feature_dim,)\n",
        "\n",
        "    if dropout > 0:\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "    return models.Model(inp, out, name=\"mobilenetv3_2d_baseline\")\n",
        "\n",
        "model = build_2d_baseline(\n",
        "    input_shape=(CFG[\"T\"], CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"], 3),\n",
        "    num_classes=num_classes,\n",
        "    dropout=CFG[\"DROPOUT\"]\n",
        ")\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "i9L932vr_Hdv",
        "outputId": "ab91cf97-5823-4001-8c4a-2232bf488160"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/applications/mobilenet_v3.py:452: UserWarning: `input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  return MobileNetV3(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
            "\u001b[1m4334752/4334752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mobilenetv3_2d_baseline\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mobilenetv3_2d_baseline\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m576\u001b[0m)        │       \u001b[38;5;34m939,120\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m28,850\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,850</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m967,970\u001b[0m (3.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">967,970</span> (3.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m955,858\u001b[0m (3.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">955,858</span> (3.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m12,112\u001b[0m (47.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,112</span> (47.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_optimizer(steps_per_epoch=None):\n",
        "    lr, wd = CFG[\"BASE_LR\"], CFG[\"WEIGHT_DECAY\"]\n",
        "    if CFG[\"COSINE\"] and steps_per_epoch:\n",
        "        total_steps = steps_per_epoch * CFG[\"EPOCHS\"]\n",
        "        warmup_steps = CFG[\"WARMUP_EPOCHS\"] * steps_per_epoch\n",
        "        def schedule(step):\n",
        "            step = tf.cast(step, tf.float32)\n",
        "            lr_warm = lr * (step / tf.cast(max(1,warmup_steps), tf.float32))\n",
        "            lr_cos  = 0.5*lr*(1.0+tf.cos(np.pi*(step-warmup_steps)/tf.cast(max(1,total_steps-warmup_steps), tf.float32)))\n",
        "            return tf.where(step<warmup_steps, lr_warm, lr_cos)\n",
        "        lr_schedule = tf.keras.optimizers.schedules.LearningRateSchedule(schedule)\n",
        "        return tf.keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=wd, global_clipnorm=CFG[\"CLIP_NORM\"])\n",
        "    return tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=wd, global_clipnorm=CFG[\"CLIP_NORM\"])\n",
        "\n",
        "def compile_model(model, steps_per_epoch=None):\n",
        "    opt = build_optimizer(steps_per_epoch)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=CFG[\"LABEL_SMOOTHING\"])\n",
        "    metrics = [tf.keras.metrics.TopKCategoricalAccuracy(k=1, name=\"top1\"),\n",
        "               tf.keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5\")]\n",
        "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
        "    return model\n",
        "\n",
        "def build_callbacks(out_dir: str):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    return [\n",
        "        tf.keras.callbacks.TerminateOnNaN(),\n",
        "        tf.keras.callbacks.ModelCheckpoint(os.path.join(out_dir,\"ckpt_best.weights.h5\"),\n",
        "                                           monitor=\"val_top1\", mode=\"max\",\n",
        "                                           save_best_only=True, save_weights_only=True),\n",
        "        tf.keras.callbacks.EarlyStopping(monitor=\"val_top1\", mode=\"max\", patience=5, restore_best_weights=True),\n",
        "        tf.keras.callbacks.CSVLogger(os.path.join(out_dir,\"train_log.csv\"))\n",
        "    ]\n",
        "\n",
        "steps_per_epoch = None if (not CFG[\"DRY_RUN\"] or not CFG[\"MAX_STEPS\"]) else CFG[\"MAX_STEPS\"]\n",
        "model = compile_model(model, steps_per_epoch)\n",
        "callbacks = build_callbacks(CFG[\"ARTIFACTS_DIR\"])"
      ],
      "metadata": {
        "id": "IAWEPS2o_JJC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "def evaluate_and_log(model, dataset, class_names, run_name=\"test_2d\"):\n",
        "    \"\"\"\n",
        "    Evaluiert das Modell auf dataset und loggt Ergebnisse in MLflow.\n",
        "    \"\"\"\n",
        "    y_true, y_pred, y_pred_top5 = [], [], []\n",
        "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "    losses = []\n",
        "\n",
        "    for xb, yb in dataset:\n",
        "        probs = model(xb, training=False).numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        preds_top5 = np.argsort(probs, axis=1)[:, -5:]\n",
        "        labels = np.argmax(yb.numpy(), axis=1)\n",
        "\n",
        "        y_true.extend(labels)\n",
        "        y_pred.extend(preds)\n",
        "        y_pred_top5.extend(preds_top5)\n",
        "        losses.append(loss_fn(yb, probs).numpy())\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_pred_top5 = np.array(y_pred_top5)\n",
        "    avg_loss = float(np.mean(losses))\n",
        "\n",
        "    # --- Top1 / Top5 ---\n",
        "    top1 = float((y_true == y_pred).mean())\n",
        "    top5 = float(np.mean([yt in yp for yt, yp in zip(y_true, y_pred_top5)]))\n",
        "\n",
        "    # --- Confusion Matrix ---\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, xticklabels=class_names, yticklabels=class_names,\n",
        "                cmap=\"Blues\", cbar=True)\n",
        "    plt.title(f\"Confusion Matrix ({run_name})\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    cm_png = os.path.join(CFG[\"ARTIFACTS_DIR\"], f\"confusion_matrix_{run_name}.png\")\n",
        "    plt.tight_layout(); plt.savefig(cm_png, dpi=150); plt.close()\n",
        "    mlflow_log_artifact(cm_png)\n",
        "\n",
        "    # --- Per-Class Report ---\n",
        "    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    report_csv = os.path.join(CFG[\"ARTIFACTS_DIR\"], f\"class_report_{run_name}.csv\")\n",
        "    report_df.to_csv(report_csv)\n",
        "    mlflow_log_artifact(report_csv)\n",
        "\n",
        "    # --- Metrics JSON ---\n",
        "    mlflow.log_metrics({\n",
        "        f\"{run_name}_loss\": avg_loss,\n",
        "        f\"{run_name}_top1\": top1,\n",
        "        f\"{run_name}_top5\": top5\n",
        "    })\n",
        "\n",
        "    print(f\"[Eval-{run_name}] Top1={top1:.3f}, Top5={top5:.3f}, Loss={avg_loss:.3f}\")\n",
        "    return {\"loss\": avg_loss, \"top1\": top1, \"top5\": top5}\n",
        "\n",
        "# =========================================================\n",
        "# Training + Eval + Logging (2D-Baseline)\n",
        "# =========================================================\n",
        "run_name = f\"2D_BASE_mobilenetv3_T{CFG['T']}_s{CFG['STRIDE']}\"\n",
        "tags = {\n",
        "    \"run_group\": \"2D_BASELINE\",\n",
        "    \"model_family\": \"2D\",\n",
        "    \"backbone\": \"mobilenetv3_small\",\n",
        "    \"fine_tune\": CFG[\"FINE_TUNE\"],\n",
        "    \"head\": \"temporal_avg\",\n",
        "    \"baseline\": \"true\"\n",
        "}\n",
        "params = {\n",
        "    \"epochs\": CFG[\"EPOCHS\"],\n",
        "    \"batch_size\": CFG[\"BATCH\"],\n",
        "    \"base_lr\": CFG[\"BASE_LR\"]\n",
        "}\n",
        "\n",
        "_ = mlflow_start(run_name, tags, params)\n",
        "print(\"MLflow run gestartet:\", run_name)\n",
        "\n",
        "# --- Training ---\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_val,\n",
        "    epochs=CFG[\"EPOCHS\"],\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# --- Lernkurven speichern & loggen ---\n",
        "curves_png = os.path.join(CFG[\"ARTIFACTS_DIR\"], \"curves_2d.png\")\n",
        "plt.figure()\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(history.history[\"top1\"], label=\"train_top1\")\n",
        "plt.plot(history.history[\"val_top1\"], label=\"val_top1\")\n",
        "plt.legend(); plt.xlabel(\"epoch\"); plt.ylabel(\"metric\")\n",
        "plt.title(\"Training Curves (2D)\")\n",
        "plt.savefig(curves_png); plt.close()\n",
        "mlflow_log_artifact(curves_png)\n",
        "\n",
        "# --- Evaluation auf Testset ---\n",
        "evaluate_and_log(model, ds_test, class_names, run_name=\"test_2d\")\n",
        "\n",
        "# --- Run schließen ---\n",
        "mlflow_end()\n",
        "print(\"Training + Evaluation (2D-Baseline) beendet & MLflow-Run geschlossen.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GuQMnUj_MJO",
        "outputId": "6a38bed4-d0b8-4b8a-c5d2-95023a66d4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow run gestartet: 2D_BASE_mobilenetv3_T16_s2\n",
            "Epoch 1/30\n",
            "     63/Unknown \u001b[1m904s\u001b[0m 73ms/step - loss: 4.0148 - top1: 0.0482 - top5: 0.2273"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/28 14:30:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1191s\u001b[0m 5s/step - loss: 4.0070 - top1: 0.0484 - top5: 0.2287 - val_loss: 4.4013 - val_top1: 0.0163 - val_top5: 0.0924\n",
            "Epoch 2/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - loss: 2.6606 - top1: 0.1392 - top5: 0.5428 - val_loss: 4.8298 - val_top1: 0.0163 - val_top5: 0.1005\n",
            "Epoch 3/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 2s/step - loss: 2.3749 - top1: 0.2703 - top5: 0.6764 - val_loss: 6.7552 - val_top1: 0.0082 - val_top5: 0.0897\n",
            "Epoch 4/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 2s/step - loss: 2.1681 - top1: 0.3070 - top5: 0.7270 - val_loss: 29.5912 - val_top1: 0.0272 - val_top5: 0.1114\n",
            "Epoch 5/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 1.9591 - top1: 0.3943 - top5: 0.7518"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HqH8ZwKJAcuZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}